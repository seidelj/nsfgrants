<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Lexicalized Reasoning</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>69474</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>James Donlon</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Many problems in artificial intelligence form natural pairs of a recognition and generation problem. For example, parsing natural language sentences, and generating new natural language sentence are natural inverses. Similarly, recognizing the plans being executed by others and building our own plans seem intimately intertwined. Unfortunately research on methods to solve these problems has often required specialized representations and algorithms. As a result, unified models of intelligence remain elusive and the results from one problem area do not translate to another. This project is part of a research program based on the idea that unified models of intelligence require unifying representations and algorithms across research problems. In particular, in the last ten years, Steedman's Combinatory Categorial Grammars (CCGs), which had already been shown to be successful in both natural language parsing and generation, have been shown to be effective for both directing probabilistic plan recognition and planning. This gives us good evidence for seeing CCGs as a unifying representation. However, this success immediately raises the question where do such grammars come from, and can they be learned? The main goal of this project is to begin to answer this question.&lt;br/&gt;&lt;br/&gt;Natural language researchers have proposed a number of methods for learning CCGs for natural languages. However, none of these methods have been applied to the learning of grammars for plans. Therefore, this project is the first exploration of these algorithms for learning grammars to direct plan recognition and planning. Specifically, the focus of this work will be to modify a recently published algorithm for learning natural language CCGs to learn plan grammars. We will use input datasets generated from the publicly available International Planning Competition domains and attempt to learn grammars to both recognize future instance of plans and to direct the construction of future plan instances. We will evaluate the effectiveness of the learned plan CCGs using traditional metrics from language grammar learning. In addition, since these CCGs are intended specifically to direct planning and plan recognition, we will measure the effectiveness of the resulting CCG at these problems using the traditional metrics from these research areas. For planning this includes runtime and length of plan, and for plan recognition accuracy, runtime, and mean time to recognition.</AbstractNarration>
    <MinAmdLetterDate>08/30/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>08/30/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1650204</AwardID>
    <Investigator>
      <FirstName>Christopher</FirstName>
      <LastName>Geib</LastName>
      <EmailAddress>cwg33@drexel.edu</EmailAddress>
      <StartDate>08/30/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Drexel University</Name>
      <CityName>Philadelphia</CityName>
      <ZipCode>191021119</ZipCode>
      <PhoneNumber>2158955849</PhoneNumber>
      <StreetAddress>1505 Race St, 8th Floor</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
