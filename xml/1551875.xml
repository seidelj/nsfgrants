<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Research in the Interface of Algorithmic Game Theory and Learning</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2016</AwardExpirationDate>
    <AwardAmount>225000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tracy J. Kimbrel</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Recent years have seen tremendous advances in Machine Learning and in the interface between Computer Science and Economics. Progress in Machine Learning has been driven by the vast amounts of data that humanity is generating and collecting. It is now widely accepted that scientific innovation necessitates the development of computational methodology to process this data and use it for inference and prediction. This has resulted in remarkable progress at the interface of Algorithms, Machine Learning and Statistics. At the same time, much of the world's economic activity has been transferred to the Internet via old markets that obtained online presence as well as new markets that are directly inspired and enabled by online activity, such as sponsored search and ad auctions. Driven by the increasing importance of online economic activity there has been much interest in investigating its joint computational and economic characteristics through research at the interface of Computer Science and Economics, which includes Algorithmic Game Theory.&lt;br/&gt;&lt;br/&gt;The PI and his group at MIT have made several contributions to both Learning and Algorithmic Game Theory. The goal of the proposed research is to push the research front in the interface between these two fields.&lt;br/&gt;&lt;br/&gt;The PI and his team plan to pursue 4 goals, as follows. Goal (1) is to advance understanding of learning dynamics in games. Goal (2) is to design "learning mechanisms'' to solve learning and inference tasks when the only access to data is through strategic data providers with a cost for producing good data. Besides online learning, the team expects that advances in (1) will have implications to fundamental problems in Algorithmic Game Theory, particularly in goal (3): improving the state-of-the-art in algorithms for the computation of approximate Nash equilibria. Progress in (2) will have immediate applications in crowd-sourcing, but the team also plans to investigate another application, motivated by the tremendous growth of Massive Online Open Courses: goal (4) is to develop good peer grading schemes.</AbstractNarration>
    <MinAmdLetterDate>08/25/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/25/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1551875</AwardID>
    <Investigator>
      <FirstName>Constantinos</FirstName>
      <LastName>Daskalakis</LastName>
      <EmailAddress>costis@csail.mit.edu</EmailAddress>
      <StartDate>08/25/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Massachusetts Institute of Technology</Name>
      <CityName>Cambridge</CityName>
      <ZipCode>021394301</ZipCode>
      <PhoneNumber>6172531000</PhoneNumber>
      <StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7796</Code>
      <Text>ALGORITHMIC FOUNDATIONS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7932</Code>
      <Text>COMPUT GAME THEORY &amp; ECON</Text>
    </ProgramReference>
  </Award>
</rootTag>
