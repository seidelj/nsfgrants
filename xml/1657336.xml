<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CRII: SHF: Design and Analysis of Processing-Near-Memory Enabled GPU Architecture</AwardTitle>
    <AwardEffectiveDate>02/01/2017</AwardEffectiveDate>
    <AwardExpirationDate>01/31/2019</AwardExpirationDate>
    <AwardAmount>175000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tao Li</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Graphics Processing Units (GPUs) are becoming an inevitable part of every computing system because of their ability to enable orders of magnitude faster and energy-efficient execution. However, the necessary and continuous scaling of GPUs in terms of performance and energy efficiency will not be an easy task. Prior works have shown that two biggest impediments towards this scaling are the limited memory bandwidth and the excessive data movement across different levels of the memory hierarchy. In order to alleviate these two issues, die-stacking technology is gaining momentum in the realm of high-performance energy-efficient GPU computing. This technology not only enables very high memory bandwidth for better performance but also provides support for processing-near-memory (PNM) to reduce data movement, access latencies, and energy consumption. Although these technologies seem promising, the architectural support and execution models for PNM-based GPUs and their implications on the entire system design have largely been unexplored. This project takes a fresh look at the design and execution model of a PNM-enabled GPU, which consists of multiple memory stacks and each memory stack incorporates a 3D-stacked logic layer that can consist of multiple PNM GPU cores and other uncore components. Considering that GPUs are becoming an inevitable part of every computing system ranging from warehouse-scale computers to wearable devices, the insights resulting from this research can have a long-term positive impact on the GPU-based computing. The findings of this research will be incorporated to existing and new undergraduate and graduate courses, which will directly help in educating and training students, including women and students from diverse backgrounds and minority groups.&lt;br/&gt;&lt;br/&gt;First, a detailed design space exploration will be performed, which will involve the study of the impact and interactions of different design choices related to PNM cores (e.g., register file, SIMD width, pipeline components, warp occupancy), uncore components at the logic layer (e.g., caches) and stacked memory (e.g., number of stacked memories). Second, a computation distribution framework (CDF) will be developed that will answer: a) when is it preferable to map computations to PNM cores, b) which PNM cores and computations they should be?, and c) how can we effectively take advantage of both PNM and regular GPU cores? The CDF will leverage different static and runtime strategies to address many of such similar questions to push the envelopes of energy efficiency and performance even further. The proposed research components will be evaluated via a wide-range of GPGPU applications.  If successful, the findings of this research would better equip PNM-enabled GPUs to effectively alleviate the two major bottlenecks: memory bandwidth and energy.</AbstractNarration>
    <MinAmdLetterDate>01/25/2017</MinAmdLetterDate>
    <MaxAmdLetterDate>01/25/2017</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1657336</AwardID>
    <Investigator>
      <FirstName>Adwait</FirstName>
      <LastName>Jog</LastName>
      <EmailAddress>adwait@cs.wm.edu</EmailAddress>
      <StartDate>01/25/2017</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>College of William and Mary</Name>
      <CityName>Williamsburg</CityName>
      <ZipCode>231878795</ZipCode>
      <PhoneNumber>7572213966</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Virginia</StateName>
      <StateCode>VA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>026Y</Code>
      <Text>CRII CISE Research Initiation</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7941</Code>
      <Text>COMPUTER ARCHITECTURE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8228</Code>
      <Text>CISE Resrch Initiatn Initiatve</Text>
    </ProgramReference>
  </Award>
</rootTag>
