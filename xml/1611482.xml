<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Creating a new assessment tool for quantitative critical thinking in introductory lab courses</AwardTitle>
    <AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2019</AwardExpirationDate>
    <AwardAmount>299176</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>11040000</Code>
      <Directorate>
        <LongName>Direct For Education and Human Resources</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Undergraduate Education</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Kevin Lee</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>A great deal of time and money is spent on science lab classes, but there is little evidence they are providing good educational value, and some indication that they are not. Currently, there are no accepted ways to measure whether or not students are learning the desired skills from such classes. This significant project will create a new way to measure students' learning of a particularly important set of skills that such labs can teach: how students reason with experimental data and test the validity of scientific models. These skills are an essential part of all science and are also important in public policy decisions and throughout the technical workforce. This test will be easy to administer to students and will guide instructional improvement. It will provide an essential first step for enabling the widespread improvement of the educational effectiveness of lab courses. &lt;br/&gt;&lt;br/&gt;Investigators on this project will develop and validate an easy-to-use assessment of quantitative critical thinking skills in the context of introductory physics lab courses. The concise and validated assessment tool will be critical to building evidence about the effectiveness of laboratory instruction and to generate new knowledge about student competencies and difficulties in critical thinking and scientific decision making. The specific set of skills to be assessed include interpreting and drawing conclusions from data with uncertainties, comparing and evaluating models and data, and making decisions about improving the experimental design or data acquisition. These skills were identified as key goals for an undergraduate science curriculum and for which labs have unique affordances for teaching. Development of the instrument will involve cycles of revisions through: evaluating think-aloud interviews with students and experts; evaluating written responses from a wide range of students enrolled in physics lab courses; and through statistical tests of reliability and validity.</AbstractNarration>
    <MinAmdLetterDate>06/17/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>11/30/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1611482</AwardID>
    <Investigator>
      <FirstName>Carl</FirstName>
      <LastName>Wieman</LastName>
      <EmailAddress>cwieman@stanford.edu</EmailAddress>
      <StartDate>06/17/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Stanford University</Name>
      <CityName>Palo Alto</CityName>
      <ZipCode>943041212</ZipCode>
      <PhoneNumber>6507232300</PhoneNumber>
      <StreetAddress>3160 Porter Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1998</Code>
      <Text>IUSE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>8209</Code>
      <Text>Improv Undergrad STEM Ed(IUSE)</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9178</Code>
      <Text>UNDERGRADUATE EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
