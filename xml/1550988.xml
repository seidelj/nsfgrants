<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Development of Temporal Visual Selective Attention in Deaf Children</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2019</AwardExpirationDate>
    <AwardAmount>449947</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Laura Namy</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The human brain is remarkably adept at integrating information from the different senses to create rich representations of the world. For example, understanding what a dog is can involve information not only about how the dog looks and acts, but also about how it sounds, feels, and even smells. Consequently, one sense, such as hearing, can exert an influence on processing in another, such as vision. There has been some suggestion from prior research that this is why deaf children often struggle to process some types of visual information. However, this may not be due to a direct effect of lack of hearing on vision. Deaf children often have delayed exposure to language, which may also influence how children's visual processing develops. The effects of language exposure and auditory deprivation can be disentangled by studying deaf children who are exposed to a natural visual language - American Sign Language. This project will provide information about how hearing and language influence vision during development, and will also provide information about how deaf children come to learn about the world around them.&lt;br/&gt;&lt;br/&gt;One hundred and fifty deaf children aged 6-13 years, who vary in both their hearing loss and their exposure to American Sign Language, will be followed longitudinally for 2-3 years. During the first wave of data collection, each child's audiological profile, ASL skills and language background, and nonverbal IQ will be assessed. At each of four waves of data collection, their ability to process sequential streams of visual information will be measured. Moderation analyses will be used to determine the effects of hearing loss and natural language exposure and skill on the development of this visual processing ability. In doing so, the researchers will be able to test competing hypotheses about the basis for visual sequence processing deficits in deaf children.</AbstractNarration>
    <MinAmdLetterDate>02/22/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>02/22/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1550988</AwardID>
    <Investigator>
      <FirstName>Matthew</FirstName>
      <LastName>Dye</LastName>
      <EmailAddress>mwddls@rit.edu</EmailAddress>
      <StartDate>02/22/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Rochester Institute of Tech</Name>
      <CityName>ROCHESTER</CityName>
      <ZipCode>146235603</ZipCode>
      <PhoneNumber>5854757987</PhoneNumber>
      <StreetAddress>1 LOMB MEMORIAL DR</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1698</Code>
      <Text>DEVELOP&amp; LEARNING SCIENCES/CRI</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1698</Code>
      <Text>DEVELOP&amp; LEARNING SCIENCES/CRI</Text>
    </ProgramReference>
  </Award>
</rootTag>
