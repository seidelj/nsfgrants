<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SL-CN: Cortical Architectures for Robust Adaptive Perception and Action</AwardTitle>
    <AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>749779</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04010000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>SBE Off Of Multidisciplinary Activities</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Charles Kalish</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The motivation for this biologically-inspired approach is to design systems that perceive and act in cluttered and noisy scenes that they have never experienced. This stands in contrast with the state of the art in computational engineering systems that need to be re-trained each time they confront an unanticipated environment. The main reason is that current approaches to perception address specific problems in isolation and do not consider that the primary role of perception is to support systems with bodies in action. As a result, they are constrained to the situations for which they were trained and cannot react to changing tasks and scenes. By focusing on cognition primitives rather than specific applications, the work is expected to greatly advance the state of the art of machine perception and lead to the development of systems that can robustly and on-line adapt to new environments, react to novel situations and learn new contexts. To do so, novel theoretical formulations of perception and action and high-speed, low-power, hardware implementations with on-line learning capabilities will be studied while assimilating new insights from the neurosciences. Consequently, this work will network neuroscience, cognitive science, applied mathematics, computer science and engineering so as to lower one of the few remaining barriers that keeps interactive robots in the realm of science fiction. Beyond the scholarly contribution, the work is expected to provide know-how for the design of systems with adaptive perception in a modular fashion with reusable components. Such systems have applications in computational vision and auditory perception problems and can advance the industry of cognitive biologically-inspired robotics and assistive devices.&lt;br/&gt;&lt;br/&gt;This proposal sets forward novel ideas in the design of intelligent perceptual systems and the development of synthetic intelligence. Just about any task which an intelligent system solves involves the interplay of four basic processes that are devoted to: (a) context, (b) attention, (c) segmentation and (d) categorization. The members of the proposed network will study these canonical cognitive primitives by combining neural modeling with neural and behavioral experiments, theoretical and computational modeling and implementation in robotics. The findings of theoretical insights will then be adapted to satisfy the demands of realistic behavior, and to develop technological solutions for applications of robust and invariant perception and action. The proposed collaborative network will consist of a small science and engineering research team to directly address the questions in robust adaptive perception and action. It will then direct personnel, and inject results and pedagogical content to a Summer Workshop that aims to include a global network of researchers.</AbstractNarration>
    <MinAmdLetterDate>08/20/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/20/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1540916</AwardID>
    <Investigator>
      <FirstName>Shihab</FirstName>
      <LastName>Shamma</LastName>
      <EmailAddress>sas@isr.umd.edu</EmailAddress>
      <StartDate>08/20/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Andreas</FirstName>
      <LastName>Andreou</LastName>
      <EmailAddress>andreou@jhu.edu</EmailAddress>
      <StartDate>08/20/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Cornelia</FirstName>
      <LastName>Fermuller</LastName>
      <EmailAddress>fer@cfar.umd.edu</EmailAddress>
      <StartDate>08/20/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Timothy</FirstName>
      <LastName>Horiuchi</LastName>
      <EmailAddress>timmer@isr.umd.edu</EmailAddress>
      <StartDate>08/20/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Ralph</FirstName>
      <LastName>Etienne-Cummings</LastName>
      <EmailAddress>retienne@jhu.edu</EmailAddress>
      <StartDate>08/20/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Maryland College Park</Name>
      <CityName>COLLEGE PARK</CityName>
      <ZipCode>207425141</ZipCode>
      <PhoneNumber>3014056269</PhoneNumber>
      <StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Maryland</StateName>
      <StateCode>MD</StateCode>
    </Institution>
    <ProgramElement>
      <Code>004Y</Code>
      <Text>Science of Learning</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7278</Code>
      <Text>SCIENCE OF LEARN CTRS- CENTERS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7298</Code>
      <Text>COLLABORATIVE RESEARCH</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7956</Code>
      <Text>SBE Interdisciplinary Research</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8089</Code>
      <Text>Understanding the Brain/Cognitive Scienc</Text>
    </ProgramReference>
  </Award>
</rootTag>
