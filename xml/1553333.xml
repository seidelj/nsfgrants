<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Optimizing Computational Range and Velocity Imaging</AwardTitle>
    <AwardEffectiveDate>02/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>01/31/2021</AwardExpirationDate>
    <AwardAmount>83050</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project focuses on developing optimized hardware and software implementations for emerging computational range and velocity imaging. Today, the primary technologies for capturing range and velocity are radar and lidar. These offer a very high precision, but available systems are expensive, bulky, and slow, because they sequentially scan scenes in a point-by-point manner. Time-of-flight (ToF) cameras have emerged as inexpensive and fast alternatives. ToF cameras use active, temporally-modulated illumination and coded, in-pixel sensing to estimate the distance between the camera and each scene point in three dimensions (3D). Recently, simultaneous range and velocity imaging techniques were demonstrated for the first time with ToF cameras. A major roadblock for unlocking the full, transformative potential of range and velocity imaging has been the limited access to low-level sensor and illumination functionalities of commercially-available ToF cameras. Range (or depth) and velocity imaging enables computers to sense and understand the world and 3D scene dynamics. A wide range of applications in medical imaging, defense, human-computer interaction, and robotics rely on depth and velocity information to perform domain-specific tasks, such as object detection, tracking, localization, mapping, and motion analysis.&lt;br/&gt;&lt;br/&gt;This research makes computational range and velocity imaging practical by optimizing the speed, resolution, precision of depth and velocity estimation, 3D imaging capabilities, and photon sensitivity of emerging computational imaging systems in direct and non-line-of-sight scenarios. By analyzing the fundamental limitations and benefits of time-resolved imaging systems, optimized hardware implementations and reconstruction algorithms are devised that facilitate novel range and velocity sensing capabilities and make them practical (i.e. robust, inexpensive, and reproducible). The anticipated insights and contributions advance knowledge and gain an understanding of the limits of time-resolved computational imaging and how to practically achieve them. The developed computational imaging systems and mathematical models are expected to provide fundamentally new building blocks for a diversity of applications in computer and machine vision, medical imaging, microscopy, scientific imaging, remote sensing, defense, and robotics.</AbstractNarration>
    <MinAmdLetterDate>01/11/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>01/11/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1553333</AwardID>
    <Investigator>
      <FirstName>Gordon</FirstName>
      <LastName>Wetzstein</LastName>
      <EmailAddress>gordon.wetzstein@stanford.edu</EmailAddress>
      <StartDate>01/11/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Stanford University</Name>
      <CityName>Palo Alto</CityName>
      <ZipCode>943041212</ZipCode>
      <PhoneNumber>6507232300</PhoneNumber>
      <StreetAddress>3160 Porter Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
  </Award>
</rootTag>
