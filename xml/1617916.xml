<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Measurable Program Analysis</AwardTitle>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardAmount>507653</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Software is everywhere and its correct operation plays an increasingly important role in the health, productivity, and safety of society and in the lives of individuals.  Consequently, there is a need for techniques that can cost-effectively measure software correctness to establish a well-founded basis for making judgments about whether software is ready for deployment and wide spread use.  The availability of such measures provides an evidentiary basis  for balancing the rewards of using a software system against the risks of its failure.  This type of evidence has the potential to transform the expectations of consumers of software and to enhance their understanding of software behavior and how to place their trust in that behavior.  Evidence of correctness has obvious value for safety critical software, but more broadly it will help shape how society views software as critical infrastructure and the professionalism that it expects of its manufacture.&lt;br/&gt;&lt;br/&gt;This project blends the outcomes of decades of work on abstraction-based program analysis and symbolic execution with recent results in quantifying the solution space of a logical formula.  The project explores novel combinations and staging of scalable non-quantitative analyses, to identify sub-spaces of program behavior that may be erroneous, followed by quantitative analyses focused on those sub-spaces.  This offers an approach to measurable program analysis (MPA) that promises scalability while yielding safe and accurate results.  The project produces theory and tools that realize a variety of MPA, empirically evaluates the cost and benefit of these analyses, and openly shares all results and artifacts with the research community.</AbstractNarration>
<MinAmdLetterDate>05/16/2016</MinAmdLetterDate>
<MaxAmdLetterDate>04/30/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1617916</AwardID>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Dwyer</LastName>
<EmailAddress>dwyer@cse.unl.edu</EmailAddress>
<StartDate>05/16/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Nebraska-Lincoln</Name>
<CityName>Lincoln</CityName>
<ZipCode>685031435</ZipCode>
<PhoneNumber>4024723171</PhoneNumber>
<StreetAddress>151 Prem S. Paul Research Center</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<StateCode>NE</StateCode>
</Institution>
<ProgramElement>
<Code>7798</Code>
<Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8206</Code>
<Text>Formal Methods and Verification</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
</ProgramReference>
</Award>
</rootTag>
