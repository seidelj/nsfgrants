<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CHS: Small: Collaborative Research: Modeling Social Context to Improve Human-Robot Interaction</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>250000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>For robots to be truly useful to people, it is critical that they be able to understand and operate independently in human social environments (HSEs). Decades of research into this problem by many investigators have to date failed to yield a solution. The PIs on this collaborative project that spans two partner institutions argue that a fundamental paradigm shift is necessary to enable progress, and that this shift can be ignited through a contextually driven approach to mobile robotics. Thus, the goal of this proposal is to create and evaluate new models of social context in order to enable mobile robots to interact appropriately with people in HSEs. Project outcomes will help give all "things that think", from social robots to smart homes, a better understanding of human social context and a greater capability to operate effectively in real-world human spaces. By contributing new theoretical models, techniques, and open source implementations that will accelerate the development and adoption of machines that operate in HSEs, the PIs anticipate this work will have a transformative impact on many fields within computer and information science, including robotics, human-machine interaction, and ubiquitous computing. The PIs also will make their context models available to other researchers. &lt;br/&gt;&lt;br/&gt;The PIs' approach to context is unique in that, rather than being techno-centric and entirely representational, it fully adopts Dourish's approach to an interactional model of context inspired by the social sciences - relational, dynamic, occasioned, and arising from activity - i.e., fluid. The key contribution of the approach is that it ties real-time sensor data to models of situational context, which then inform a robot of the social affordances of the environment. The PIs will engage in two primary research activities. First, they will create a situational context processing capability that can accept a multimodal, social scene snapshot from a robot and return back a situational context frame (SCF) that contains an estimate of the scene's salient objects, social activities, and situational context. Then, they will contribute algorithmic techniques that enable a robot to leverage the SCF to perform guided exploration to refine its model, and ultimately, goal-driven task execution adapted to conform to social norms. The PIs' research emphasis on using solely naturalistic, real-world, multimodal data, will enable them to make unique contributions for increasing robustness in multimodal processing.</AbstractNarration>
    <MinAmdLetterDate>08/20/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/20/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1527759</AwardID>
    <Investigator>
      <FirstName>Laurel</FirstName>
      <LastName>Riek</LastName>
      <EmailAddress>lriek@cse.nd.edu</EmailAddress>
      <StartDate>08/20/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Notre Dame</Name>
      <CityName>NOTRE DAME</CityName>
      <ZipCode>465565708</ZipCode>
      <PhoneNumber>5746317432</PhoneNumber>
      <StreetAddress>940 Grace Hall</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Indiana</StateName>
      <StateCode>IN</StateCode>
    </Institution>
  </Award>
</rootTag>
