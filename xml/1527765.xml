<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>III: Small: Collaborative Research: Towards Interactive Data Visualization Management Systems</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>248866</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Maria Zemankova</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Interactive visualizations are a powerful way to explore and draw insights from data. As the data available to practitioners continues to grow in complexity and size, existing systems find it harder and harder to maintain a highly interactive experience. The goal of this project is to develop an interactive visual data exploration system designed and optimized to take human perception into account. The aim of this research is to model human perception as perceptual functions. These functions help the system avoid unnecessarily computing visualization results that are more accurate than what can be perceived by the end user. By developing and using these functions, the system can provide highly accurate yet interactive visualizations for large datasets in domains such as business intelligence, data-driven sciences, and healthcare analytics. In addition, research results from these efforts will contribute towards the development of new curriculum topics at the graduate level.&lt;br/&gt;&lt;br/&gt;A commonly overlooked element of interactive visualization systems is the human in the loop. Although data sizes and computational capabilities have dramatically increased over time, human perceptual limits have remained relatively constant. Although previous work has presented guidelines for effective animations [Heer et al., VCG 2007; Fisher et al., ICGA 2012] and projects such as M4 [Jugel et al., VLDB 2014] used perceptual insights to justify approximation algorithms, our goal is to build a multi-layered data analysis system that unifies interactive visualization clients with backend data management systems, and explicitly takes human perceptual models into account. These models can be used to develop perceptually-aware optimizations such as (1) automatically approximate data transformations that are perceptually indistinguishable, (2) model queries generated by an interaction (e.g., dragging a scrollbar to the right) as a single session and optimize across the entire set of queries, and (3) apply interaction-oriented caching and rewrite strategies to minimize latency. Ultimately, these techniques can ensure high frame-rate interactions for data exploration without negatively impacting the insights that users draw from their visualizations. Further information, publications and results of this research are available at the project web site (http://perceptvis.github.io).</AbstractNarration>
    <MinAmdLetterDate>08/27/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/27/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1527765</AwardID>
    <Investigator>
      <FirstName>Eugene</FirstName>
      <LastName>Wu</LastName>
      <EmailAddress>ew2493@columbia.edu</EmailAddress>
      <StartDate>08/27/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Columbia University</Name>
      <CityName>NEW YORK</CityName>
      <ZipCode>100276902</ZipCode>
      <PhoneNumber>2128546851</PhoneNumber>
      <StreetAddress>2960 Broadway</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
  </Award>
</rootTag>
