<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CIF: Small: Structured Signal Modeling via Nonconvex Optimization</AwardTitle>
    <AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2018</AwardExpirationDate>
    <AwardAmount>499778</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>John Cozzens</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Many problems in modern signal processing and data analysis can be cast as searching for a structured, low-dimensional model for observed data. Images, audio signals, video sequences, and more, can be modeled as sparse in an appropriate dictionary. Scientific data, from neural spike sorting to microscopy, can be modeled as superpositions of characteristic patterns, translated over space. Learned data representations yield excellent results on a variety of classical problems in image processing and vision, and are also play a crucial role in recent breakthroughs in signal classification and computational scientific discovery. In contrast, much less is known theoretically about the properties of learned representations, and of algorithms for learning them. This project develops theory and dedicated optimization algorithms, which are guaranteed, under appropriate conditions, to provide good representations for observed signals.&lt;br/&gt;&lt;br/&gt;The investigators study theoretical and computational aspects of a family of problems, including sparse dictionary learning, sparse deconvolution, and convolutional dictionary learning. The natural formulations of these problems are nonconvex. The goal of the project is to develop geometric insights into these nonconvex problems, and to use these insights to develop recovery theory and scalable, efficient algorithms. Key challenges include understanding the properties of local and global minima, and developing efficient algorithms that avoid stalling near saddle points. The algorithms are demonstrated on real signal data arising in image classification and scientific imaging.</AbstractNarration>
    <MinAmdLetterDate>07/27/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>07/27/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1527809</AwardID>
    <Investigator>
      <FirstName>Donald</FirstName>
      <LastName>Goldfarb</LastName>
      <EmailAddress>goldfarb@columbia.edu</EmailAddress>
      <StartDate>07/27/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>John</FirstName>
      <LastName>Wright</LastName>
      <EmailAddress>jw2966@columbia.edu</EmailAddress>
      <StartDate>07/27/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Columbia University</Name>
      <CityName>NEW YORK</CityName>
      <ZipCode>100276902</ZipCode>
      <PhoneNumber>2128546851</PhoneNumber>
      <StreetAddress>2960 Broadway</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
  </Award>
</rootTag>
