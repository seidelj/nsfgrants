<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Robots that Help People</AwardTitle>
    <AwardEffectiveDate>03/15/2017</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2022</AwardExpirationDate>
    <AwardAmount>102696</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Reid Simmons</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>As robots become more prevalent, it is crucial to develop ways for people to collaborate with them. This proposal aims to create collaborative robots through a combination of communication, perception, and action. Existing approaches are typically tailored to specific applications; yet people want to talk to robots about everything they can see and do. To address such limitations, this project will create a unified framework to enable robots to communicate with people to learn their needs, plan how to achieve them, and then perceive and act in the world in order to meet those needs. The research will be demonstrated with robots that can assist with household tasks, such as cooking and cleaning, as well as in manufacturing settings, such as collaborative assembly. The project will expose many people to collaborative robotics through an internship program with local high schools, a regional robotics conference, and the Million Object Challenge.&lt;br/&gt;&lt;br/&gt;This project will create a model, the Human-Robot Collaborative Partially Observable Markov Decision Process, that enables robots to 1) automatically acquire object-oriented models of objects in the physical world; 2) communicate with people to understand their needs and how to meet them; and 3) act to change the world in ways that meet people's needs. Creating a unified framework requires bridging gaps between different aspects of the robotic system. This project focuses on creating a single probabilistic graphical model to represent the robot's states and actions in a hierarchical framework, allowing the robot to make plans that take into account its own uncertainty and to communicate with a person about everything it can see and everything it can do. Focusing on collaboration leads to reformulations of traditional problems in computer vision, planning, and natural language understanding enabling the robot to collaborate in new and more natural ways.</AbstractNarration>
    <MinAmdLetterDate>03/02/2017</MinAmdLetterDate>
    <MaxAmdLetterDate>03/02/2017</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1652561</AwardID>
    <Investigator>
      <FirstName>Stefanie</FirstName>
      <LastName>Tellex</LastName>
      <EmailAddress>stefie10@cs.brown.edu</EmailAddress>
      <StartDate>03/02/2017</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Brown University</Name>
      <CityName>Providence</CityName>
      <ZipCode>029129002</ZipCode>
      <PhoneNumber>4018632777</PhoneNumber>
      <StreetAddress>BOX 1929</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Rhode Island</StateName>
      <StateCode>RI</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
  </Award>
</rootTag>
