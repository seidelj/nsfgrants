<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Belief Space Planning and Learning for Uncertainty-Immersed Underwater Robots</AwardTitle>
    <AwardEffectiveDate>06/01/2017</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2022</AwardExpirationDate>
    <AwardAmount>99812</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Reid Simmons</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The Earth's oceans and rivers are very important to our lives, and it is important to understand them in detail, such as how their current flows change over time. While it is difficult to develop detailed models of current flow from first principles, good approximations can be constructed. These coarse models can then be used by an autonomous underwater robot to plan and execute paths. By collecting data during its traversals of the environment, more detailed models can be learned, tested in simulation, and then used to make the robot's actions more reliable. This project will also contribute to the curriculum of WaterBotics, a K-12 program that exposes thousands of students to engineering principles via hands-on learning with underwater robots. The results of the proposed research will be integrated into new educational modules for this program.&lt;br/&gt;&lt;br/&gt;This project uses reinforcement learning, which has been successfully applied in learning robotic skills, to learn the dynamics of an expansive environment. Specifically, reinforcement learning will be adapted to deal with acoustic sensors whose probability distributions, due to physical disturbances and multi-path returns, vary sharply throughout the environment. The properties of these phenomena are not initially known with high accuracy, but will be learned as the robot patrols. Specifically, with a coarse initial model as a starting point, optimal policies for maneuvering and patrolling under such phenomena will be learned through a combination of planning, simulation, and physical repetition. Model-based belief space motion planning will be used to bootstrap and accelerate the episodic learning of optimal policies. The work will employ a novel belief-space planning metric that reduces the computational complexity of planning both at coarse, global scales and at fine, local scales.</AbstractNarration>
    <MinAmdLetterDate>02/28/2017</MinAmdLetterDate>
    <MaxAmdLetterDate>02/28/2017</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1652064</AwardID>
    <Investigator>
      <FirstName>Brendan</FirstName>
      <LastName>Englot</LastName>
      <EmailAddress>brendan.englot@stevens.edu</EmailAddress>
      <StartDate>02/28/2017</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Stevens Institute of Technology</Name>
      <CityName>HOBOKEN</CityName>
      <ZipCode>070305991</ZipCode>
      <PhoneNumber>2012168762</PhoneNumber>
      <StreetAddress>CASTLE POINT ON HUDSON</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
  </Award>
</rootTag>
