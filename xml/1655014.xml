<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Sociolinguistic Perception in Real Time</AwardTitle>
    <AwardEffectiveDate>06/01/2017</AwardEffectiveDate>
    <AwardExpirationDate>11/30/2020</AwardExpirationDate>
    <AwardAmount>254961</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Joan Maling</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Listeners can learn a lot of social information about a person from small details of speech, even details that they are not consciously aware of hearing. How do people put such complex information together so quickly over the course of an utterance? Sociolinguists have begun recently to study moment-to-moment reactions to each individual meaningful instance of variation. Efforts have been hampered, however, by a lack of methodological consistency and an inadequate theoretical understanding of the relationship between such moment-to-moment reactions and the end-of-stimulus judgments on which most work on sociolinguistic perception is based. Research on people's perceptions of positive and negative experiences suggests that this relationship is likely to be more complex that sociolinguists have assumed.&lt;br/&gt;&lt;br/&gt;The first phase of the project will test possible methods for tracking sociolinguistic perception moment-to-moment, including both explicit methods such as button presses and implicit methods such as eye-tracking. These will be tested on the same stimuli, which will be constructed to include specific linguistic differences, to identify the methods which are best at detecting these known differences. The successful methods will be used in the second phase to explore how listeners respond to multiple tokens of the same variable, to tokens of different but socially related variables and to variables combined with extra-linguistic information like pictures of the speaker. Finally, phase three will use the, by now, well-tested stimuli to explore the effects of important points in sociolinguistic perception on linguistic processing. The research will be conducted at the Ohio State University's Language Science Research Lab, which is embedded in the science museum COSI, inviting museum visitors to participate in the research. In addition to the core research, the project will develop more effective techniques for integrating research and outreach. Successful techniques will be shared with other institutions. Successful techniques will be shared with other institutions.</AbstractNarration>
    <MinAmdLetterDate>02/27/2017</MinAmdLetterDate>
    <MaxAmdLetterDate>02/27/2017</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1655014</AwardID>
    <Investigator>
      <FirstName>Kathryn</FirstName>
      <LastName>Campbell-Kibler</LastName>
      <EmailAddress>kbck@ling.ohio-state.edu</EmailAddress>
      <StartDate>02/27/2017</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Ohio State University</Name>
      <CityName>Columbus</CityName>
      <ZipCode>432101016</ZipCode>
      <PhoneNumber>6146888735</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Ohio</StateName>
      <StateCode>OH</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>SMET</Code>
      <Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
