<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CRCNS: Collaborative Research: Dynamic Models of Human Auditory Perceptual Switching Informed by Large-Scale ECoG Recordings</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>53427</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Kenneth C. Whang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Sounds in natural environments are complex mixtures from many different sources. This project seeks to understand how humans organize mixtures of sounds into meaningful objects. Perceptions of auditory objects arise not from any particular part of the brain, but rather from coordinated activity across many brain regions; further, binding of sounds to auditory objects may switch very rapidly. Therefore, the study of how auditory objects are formed and how rapid switching occurs requires analyzing recordings of brain activity in humans across many brain areas and at very high speed. This project aims to develop new theoretical methods for integrating and analyzing complex dynamic data sets of brain recordings from large-scale electrode arrays. The modeling approach will provide insight in the understanding of human auditory perception in both normal and clinically impaired minds. &lt;br/&gt;&lt;br/&gt;Significant advances have been made in the past three decades characterizing neural correlates of auditory perceptions localized to the auditory cortex. Nevertheless, these neural correlates are likely not restricted to the auditory cortex, or to any particular part of the brain. To understand the neural mechanisms of auditory perceptual representation and perceptual switching, the current project combines advances in both experimental design and theory. Large-scale electrocorticography (ECoG) recordings will be collected from human subjects as they self-report their perceptions during a bistable auditory task involving rapid perceptual switching. Next, spatial-temporal patterns of cortical activation during the task will be extracted from these large time-series datasets using a data-driven method novel to neuroscience known as dynamic mode decomposition (DMD). Features extracted by DMD will then be used to build data-driven, low-dimensional dynamic models that capture the temporal evolution of multiple cortical areas, encoding both the auditory stimulus and the perceptual state.</AbstractNarration>
    <MinAmdLetterDate>08/27/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/27/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1514556</AwardID>
    <Investigator>
      <FirstName>Bingni</FirstName>
      <LastName>Brunton</LastName>
      <EmailAddress>bbrunton@uw.edu</EmailAddress>
      <StartDate>08/27/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Washington</Name>
      <CityName>Seattle</CityName>
      <ZipCode>981950001</ZipCode>
      <PhoneNumber>2065434043</PhoneNumber>
      <StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Washington</StateName>
      <StateCode>WA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7327</Code>
      <Text>CRCNS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8089</Code>
      <Text>Understanding the Brain/Cognitive Scienc</Text>
    </ProgramReference>
  </Award>
</rootTag>
