<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAPSI: Real-time 3D Reconstruction for Autonomous Underwater Manipulation</AwardTitle>
<AwardEffectiveDate>06/01/2016</AwardEffectiveDate>
<AwardExpirationDate>05/31/2017</AwardExpirationDate>
<AwardAmount>5400</AwardAmount>
<AwardInstrument>
<Value>Fellowship</Value>
</AwardInstrument>
<Organization>
<Code>01090000</Code>
<Directorate>
<LongName>Office Of The Director</LongName>
</Directorate>
<Division>
<LongName>Office Of Internatl Science &amp;Engineering</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anne L. Emig</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The focus of this project is to develop and test algorithms to enable an underwater robotic system with a manipulator to sense, recognize, and retrieve an object from the seafloor, in real-time, with no user input. This work will be conducted in collaboration with Dr. Stefan Williams of the Australian Center for Field Robotics (ACFR) at the University of Sydney, Australia. Dr. Williams is an expert in the field of perception and navigation for underwater robotics, and ACFR has vehicles and facilities ideal for carrying out this work. Several applications of this work include deep-sea scientific sampling and exploration, and construction and maintenance of offshore equipment.&lt;br/&gt;&lt;br/&gt;The objective of this project is to develop novel methods for real-time underwater perception to enable autonomous intervention in aqueous environments. Methods will be developed for real-time underwater 3D reconstruction using input stereo-vision imagery for the application of autonomous grasping underwater.  These novel methods will be validated through testing on a remotely operated vehicle (ROV) equipped with stereo-vision cameras and a single function manipulator. The main goals will be to visually reconstruct an object on the seafloor in real-time and then pick up that object. Results of the 3D reconstruction will be compared to laser-acquired ground truth and through observing the interaction task with an external set of cameras to determine effectiveness in grasping. Ultimately, the results will demonstrate closed loop grasping underwater, a fundamental task for autonomous intervention, which is necessary for applications such as deep-sea scientific sampling and maintenance of offshore equipment.&lt;br/&gt;&lt;br/&gt;This award under the East Asia and Pacific Summer Institutes program supports summer research by a U.S. graduate student and is jointly funded by NSF and the Australian Academy of Science.</AbstractNarration>
<MinAmdLetterDate>06/07/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/07/2016</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1614065</AwardID>
<Investigator>
<FirstName>Katherine</FirstName>
<LastName>Skinner</LastName>
<EmailAddress/>
<StartDate>06/07/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Skinner                 Katherine      A</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481042414</ZipCode>
<PhoneNumber/>
<StreetAddress/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
</Institution>
<ProgramElement>
<Code>7316</Code>
<Text>EAPSI</Text>
</ProgramElement>
<ProgramReference>
<Code>5912</Code>
<Text>AUSTRALIA</Text>
</ProgramReference>
<ProgramReference>
<Code>5978</Code>
<Text>EAST ASIA AND PACIFIC PROGRAM</Text>
</ProgramReference>
<ProgramReference>
<Code>7316</Code>
<Text>EAPSI</Text>
</ProgramReference>
</Award>
</rootTag>
