<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Functional Imitation of Observed Tasks by Co-Robots</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2016</AwardExpirationDate>
    <AwardAmount>139968</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jeffrey Trinkle</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Assistive and service robots have made significant strides and have the potential to be transformative in many fields, including health care, aging, disability management, and work in dangerous environments. For this, however, it is important that these robots can be "programmed" and used by largely untrained users, including caregivers or elderly persons. This project aims to develop a novel approach to allow robots of widely varying designs to perform assistive and supportive tasks by observing demonstrations performed by a human. Rather than copying movement, which would require that the robot resembles the human, the proposed approach uses these demonstrations to "infer" the important aspects of the task and translate them into a strategy that can be executed by the robot and in varying situations and settings.&lt;br/&gt;&lt;br/&gt;The proposed approach treats imitation not as copying of observed movements but rather as learning to replicate the function of the demonstration. For this, it transforms observations into a hierarchical Markov task model using learned models of observed environmental dynamics. This probabilistic task model is then mapped onto a hierarchical Semi-Markov Decision model of the robot's behavioral capabilities using an adaptive similarity function that represents the correspondence between attributes in the two models as well as the importance of particular attributes for successful task performance. The cost function is adapted during imitation using Reinforcement Learning and qualitative feedback from the user, allowing the system to improve and personalize its imitation capabilities. This project develops a proof-of-concept system and evaluates it on a wheeled mobile manipulator in the context of common household tasks.</AbstractNarration>
    <MinAmdLetterDate>08/11/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/11/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1551312</AwardID>
    <Investigator>
      <FirstName>Farhad</FirstName>
      <LastName>Kamangar</LastName>
      <EmailAddress>kamangar@cse.uta.edu</EmailAddress>
      <StartDate>08/11/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Manfred</FirstName>
      <LastName>Huber</LastName>
      <EmailAddress>huber@cse.uta.edu</EmailAddress>
      <StartDate>08/11/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Gergely</FirstName>
      <LastName>Zaruba</LastName>
      <EmailAddress>zaruba@uta.edu</EmailAddress>
      <StartDate>08/11/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Arlington</Name>
      <CityName>Arlington</CityName>
      <ZipCode>760190145</ZipCode>
      <PhoneNumber>8172722105</PhoneNumber>
      <StreetAddress>1 UNIVERSITY OF TEXAS AT</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
  </Award>
</rootTag>
