<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CCF: Small: Accelerating Irregular Algorithms using Cache-Coherent FPGA Accelerators</AwardTitle>
    <AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2019</AwardExpirationDate>
    <AwardAmount>330000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tao Li</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Until recently, FPGA acceleration of computations has largely focused on algorithms that exhibit a high degree of regularity and predictability in their parallelism and memory access. The advent of high-capacity FPGA accelerators connected to the processor and main memory through a high-performance cache-coherent interconnect enables algorithms with irregular parallelism to be considered. These irregular algorithms, including many data analytic and machine learning kernels, operate on very large, memory-resident, pointer-based data structures. This project will study the opportunity to accelerate irregular algorithms for performance and energy efficiency on emerging cache-coherent FPGA accelerators. The outcome of this investigation has potential for practical commercial impact by helping to establish cache-coherent FPGA acceleration as a viable new platform option for accelerating irregular algorithms that are fundamental to datacenter workloads. This project will also provide valuable training to both graduate and undergraduate students, and improve graduate-level coursework.&lt;br/&gt;&lt;br/&gt;Instead of the traditional "off-load" model of FPGA acceleration, this project seek to develop a new tightly-coupled FPGA-processor collaboration model that takes advantage of the low-latency, fine-grain shared-memory interactions between the processor and FPGA that are now possible. The project studies fine-grain concurrent mappings of irregular algorithms where the processor and FPGA work together---each leveraging its own characteristic advantages, e.g., large cache, high frequency ALUs for the processor and energy-efficient spatial hardware concurrency for the FPGA---to outperform what either can achieve alone. An integral part of the investigation is also to develop new insights toward what should cache-coherent FPGA accelerators ultimately look like, especially with the support for irregular algorithms in mind.</AbstractNarration>
    <MinAmdLetterDate>07/27/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>07/27/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1618014</AwardID>
    <Investigator>
      <FirstName>James</FirstName>
      <LastName>Hoe</LastName>
      <EmailAddress>jhoe@ece.cmu.edu</EmailAddress>
      <StartDate>07/27/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7798</Code>
      <Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7941</Code>
      <Text>COMPUTER ARCHITECTURE</Text>
    </ProgramReference>
  </Award>
</rootTag>
