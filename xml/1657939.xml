<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Transforming data analysis via new algorithms for feature extraction</AwardTitle>
<AwardEffectiveDate>06/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardAmount>135374</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jack Snoeyink</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Analysis and exploration of data, including classification, inference, and retrieval, are ubiquitous tasks in science and applied fields. Given any such task, a fundamental paradigm is the extraction of features that are relevant. In the design of algorithms for the analysis and exploration of data, feature extraction techniques act as basic building blocks or primitives that can be combined to model complex behavior. Some of the fundamental feature extraction tools include Principal Component Analysis (PCA), Independent Component Analysis (ICA), and half-space-based learning and classification. Data rarely satisfy the precise assumptions of these models and feature extraction tools, and combining these tools amplifies errors. This motivates the challenging task of designing new algorithms that are robust against noise and that can be combined as building blocks while keeping the error propagation under control.&lt;br/&gt;&lt;br/&gt;The proposed work will:&lt;br/&gt;(1) Raise ICA from a very successful practical tool to an algorithmic primitive with strong theoretical guarantees and applicability to a rich family of problems beyond independence.&lt;br/&gt;(2) Find reasonable assumptions and algorithms that allow efficient learning of intersections of half-spaces.&lt;br/&gt;(3) Systematically study the following well-motivated refinement of PCA known as the subset selection problem. This refinement aims to select relevant features among the given features of the input data, unlike PCA, which creates new and possibly artificial features.&lt;br/&gt;&lt;br/&gt;New feature extraction algorithms enhance the toolbox available to researchers in data-intensive fields such as biology, signal processing and computer vision. They also enable improved data analysis by practitioners in security, marketing, business and government processes, and essentially any field that involves the analysis of feature-rich data. The proposed work includes the implementation of the more practical algorithms.&lt;br/&gt;&lt;br/&gt;Education and outreach aspects of this project include the mentoring of young researchers, the design of a new course for graduate and undergraduate students incorporating some of the PI's research, and the involvement of pre-college students and local communities into science and research.</AbstractNarration>
<MinAmdLetterDate>08/30/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/30/2016</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1657939</AwardID>
<Investigator>
<FirstName>Luis</FirstName>
<LastName>Rademacher</LastName>
<EmailAddress>lrademac@ucdavis.edu</EmailAddress>
<StartDate>08/30/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Davis</Name>
<CityName>Davis</CityName>
<ZipCode>956186134</ZipCode>
<PhoneNumber>5307547700</PhoneNumber>
<StreetAddress>OR/Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>7796</Code>
<Text>ALGORITHMIC FOUNDATIONS</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
</Award>
</rootTag>
