<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Whole Brain Functional Connectivity Measures of Attention</AwardTitle>
    <AwardEffectiveDate>02/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>01/31/2019</AwardExpirationDate>
    <AwardAmount>492162</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Alumit Ishai</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Attention affects nearly all aspects of perception, cognition, and performance. Despite its central importance, researchers lack a simple way to measure a person's attentional functioning. Although no mental process can be reduced to a single number, both research and practical settings can benefit from starting with standardized and quantifiable measures. For example, intelligence research and education practice depends heavily on g, an index of fluid intelligence. A comparable measure is lacking for attention. The goal of this project is to develop an attention profile measure that can 1) quantify a person's attentional function, 2) predict behavior, 3) and to facilitate comparison of attentional performance across individuals, tasks, and sites, and, importantly, over time. A quantifiable and standardized whole-brain attention measure can have transformative utility for research and practical applications. The work should have direct benefits for advancing the scientific understanding of attention and the underlying neural mechanisms. This project will also benefit society through education and research. Our brain imaging studies involve rigorous training of analytic methods needed to process complex fMRI data, providing opportunities for STEM training at high school levels and beyond, especially for women or underrepresented minorities. The PI, Dr. Marvin Chun, has a strong record of dedication to mentoring, teaching, and public outreach.&lt;br/&gt;&lt;br/&gt;The new attention profile investigated here predicts a performance ranking for novel individuals based on models of whole brain functional connectivity, which can be measured with functional magnetic resonance imaging (fMRI) during the resting state, collected while participants lie passively in the scanner without performing an explicit cognitive task. Models of intrinsic connectivity in a whole brain attention network during the resting state are created to significantly predict sustained attention task performance. This project will develop further models to test other attention components such as alerting, orienting, and executive function. Collectively, these whole brain functional connectivity models will provide a quantitative attention profile for individual participants. Because we can apply our models to novel subjects or independent data sets from different sites, these new methods have broad applicability, and they are predictive rather than just descriptive.</AbstractNarration>
    <MinAmdLetterDate>02/16/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>02/16/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1558497</AwardID>
    <Investigator>
      <FirstName>Marvin</FirstName>
      <LastName>Chun</LastName>
      <EmailAddress>marvin.chun@yale.edu</EmailAddress>
      <StartDate>02/16/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Yale University</Name>
      <CityName>New Haven</CityName>
      <ZipCode>065208327</ZipCode>
      <PhoneNumber>2037854689</PhoneNumber>
      <StreetAddress>Office of Sponsored Projects</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Connecticut</StateName>
      <StateCode>CT</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1699</Code>
      <Text>COGNEURO</Text>
    </ProgramElement>
  </Award>
</rootTag>
