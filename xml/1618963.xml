<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SHF: SMALL: Parallelization and Memory System Techniques for Heterogeneous Microprocessors</AwardTitle>
    <AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2019</AwardExpirationDate>
    <AwardAmount>400000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tao Li</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Traditional discrete GPUs have demonstrated dramatic performance gains over CPUs, but the improvements have been limited to simpler codes with massive parallelism. Recently, computer manufacturers have been producing heterogeneous microprocessors in which a CPU and GPU are integrated on the same die. Such processors provide shared memory between the CPU and GPU, and fast CPU-GPU communication. These features potentially enable acceleration of new types of computations, allowing the GPU to gainfully execute smaller loops and to support more complex codes. This project investigates techniques for exploiting heterogeneous microprocessors and to realize their benefits. If successful, the project will enable most programs, not just those with massive parallelism, to utilize GPUs. The project will also provide valuable training to both graduate and undergraduate students, and improve graduate-level coursework.&lt;br/&gt;&lt;br/&gt;On the research side, the project will pursue the following research directions. First, it will create a suite of benchmarks exhibiting complex loop nests that demonstrate the new capabilities of heterogeneous microprocessors. Second, the project will also develop novel parallelization schemes for the new benchmark suite. The parallelization schemes will map multiple levels of parallelism to CPU and GPU cores simultaneously to fully utilize the compute resources in a heterogeneous microprocessor. Third, new cache coherence protocols will be developed that efficiently support the bulk producer-consumer communication that occurs as finer-grained computations migrate from CPU to GPU and back. And finally, adaptive memory address mapping schemes will be investigated that exploit DRAM page locality for CPU accesses and channel-level parallelism for GPU accesses.</AbstractNarration>
    <MinAmdLetterDate>07/27/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>07/27/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1618963</AwardID>
    <Investigator>
      <FirstName>Donald</FirstName>
      <LastName>Yeung</LastName>
      <EmailAddress>yeung@umd.edu</EmailAddress>
      <StartDate>07/27/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Maryland College Park</Name>
      <CityName>COLLEGE PARK</CityName>
      <ZipCode>207425141</ZipCode>
      <PhoneNumber>3014056269</PhoneNumber>
      <StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Maryland</StateName>
      <StateCode>MD</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7798</Code>
      <Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7941</Code>
      <Text>COMPUTER ARCHITECTURE</Text>
    </ProgramReference>
  </Award>
</rootTag>
