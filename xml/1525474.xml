<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CNS:CSR Collaborative Research: Leveraging Intra-chip/Inter-chip Silicon-Photonic Networks for Designing Next-Generation Accelerators</AwardTitle>
    <AwardEffectiveDate>10/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2018</AwardExpirationDate>
    <AwardAmount>249828</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>M. Mimi McClure</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>A little over a decade ago, GPUs were fixed-function processors built around a pipeline, dedicated to rendering 3-D graphics. In the past decade, as the potential for GPUs to provide massive compute parallelism became apparent, the software community developed new programming environments (CUDA and OpenCL) to leverage these massively parallel devices. Today, the leading graphics vendors tailor their GPU designs for general-purpose high-performance computing by providing higher compute throughput. While GPUs are able to provide high computational throughput by launching a large number of threads, memory bandwidth and system power continue to be limiting constraints for a number of applications. &lt;br/&gt;&lt;br/&gt;This project proposes to explore the use of silicon-photonic link technology to design the intra-chip and inter-chip networks in future GPU/APU systems with the goal of addressing the memory bandwidth constraint. In particular, we will investigate the potential of the silicon-photonic networks to efficiently support the memory hierarchy of a heterogeneous design, which integrates a CPU and a GPU (i.e., an Accelerated Processing Unit (APU)) that share the same memory address space. To this end, using state-of-the-art cycle-based simulators, we will evaluate a range of memory hierarchies and intra-chip/inter-chip silicon-photonic network architectures while running a demanding set of workloads that require high memory bandwidth. Additionally, this work will explore the limits and opportunities to leverage the high-bandwidth density and low latency of the silicon-photonic networks to architect the next generations APU devices that can provide better compute throughput. It is anticipated that the results of this research will clearly demonstrate the advantages of using silicon-photonic intra-chip/inter-chip networks in the memory hierarchy of GPU and APU devices. To catalyze and sustain research in this area of APUs and silicon-photonic networks, an open-source simulator that supports intra-chip and inter-chip silicon-photonic networks will be made available to the wider accelerator/networking research communities.&lt;br/&gt;&lt;br/&gt;At a broader level, this work bridges the gap between the heterogeneous systems community and the on-chip/off-chip networks community and opens multiple opportunities for education and outreach.</AbstractNarration>
    <MinAmdLetterDate>08/19/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/19/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1525474</AwardID>
    <Investigator>
      <FirstName>Ajay</FirstName>
      <LastName>Joshi</LastName>
      <EmailAddress>joshi@bu.edu</EmailAddress>
      <StartDate>08/19/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Trustees of Boston University</Name>
      <CityName>BOSTON</CityName>
      <ZipCode>022151300</ZipCode>
      <PhoneNumber>6173534365</PhoneNumber>
      <StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
  </Award>
</rootTag>
