<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Fitting Manifolds to Noisy Data</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2019</AwardExpirationDate>
    <AwardAmount>78288</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Yong Zeng</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>In recent years, high dimensional statistics has focused on methods of alleviating the curse of dimensionality, which refers to various inconvenient phenomena that arise when analyzing data in high-dimensional spaces. One assumption that facilitates this is the Manifold hypothesis: that data lie in the vicinity of a low dimensional manifold. For example, if we randomly photograph a large number of objects, randomly choose three-by-three pixel patches, and plot the corresponding points in nine-dimensional space, we approximately see a Klein bottle, which is a two dimensional manifold. This could be due to the generating process possessing only a few essential degrees of freedom. Manifold learning is a collection of methodologies for analyzing high dimensional data based on the Manifold hypothesis. This has been an area of intense activity over the past two decades. In work with Fefferman and Mitter, the foundation for a novel approach to Manifold learning has been established. The present project is concerned with using this approach for the building of practically and theoretically efficient algorithms to fit a manifold to data, given that the data lie near a manifold.&lt;br/&gt;&lt;br/&gt;Current approaches which attempt to build a manifold with some guarantees of success, either forgo the smoothness assumption or are restrictive in some way. In the work with Fefferman and Mitter new techniques based on fiber bundles have been developed and formally justified to verify in finite time whether there is a manifold of bounded reach lying near the data. Since this is an exhaustive process, the algorithm is extremely slow. However, when the data is actually from a manifold with perhaps some corruption by noise, our approach has sufficiently powerful techniques which can be modified and adopted to construct an approximation of the manifold in near linear time on the size of the data. The feasibility of the method has been tested experimentally through implementation of the algorithm on simple examples. Theoretical guarantees of speed will be provided for these algorithms as part of this project and the algorithms will be shown to be practical. At a broader level, we would like to introduce ideas from Whitney interpolation to statistics and engineering.</AbstractNarration>
    <MinAmdLetterDate>09/08/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>09/08/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1620102</AwardID>
    <Investigator>
      <FirstName>Hariharan</FirstName>
      <LastName>Narayanan</LastName>
      <EmailAddress>harin@uw.edu</EmailAddress>
      <StartDate>09/08/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Washington</Name>
      <CityName>Seattle</CityName>
      <ZipCode>981950001</ZipCode>
      <PhoneNumber>2065434043</PhoneNumber>
      <StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Washington</StateName>
      <StateCode>WA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8069</Code>
      <Text>CDS&amp;E-MSS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7433</Code>
      <Text>CyberInfra Frmwrk 21st (CIF21)</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9263</Code>
      <Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8083</Code>
      <Text>Big Data Science &amp;Engineering</Text>
    </ProgramReference>
  </Award>
</rootTag>
