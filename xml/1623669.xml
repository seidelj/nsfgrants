<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>I-Corps: Automated Postures Analysis for Ergonomic Risk</AwardTitle>
    <AwardEffectiveDate>02/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2016</AwardExpirationDate>
    <AwardAmount>50000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Steven Konsek</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Workers in industries like manufacturing, construction, retail, health care, and logistics are involved in physically demanding activities, dealing with awkward body postures and repetitive manual handling tasks that result in ergonomic injuries (e.g., musculoskeletal disorders). For example, ergonomic injuries account for an average of 33% of nonfatal occupational injuries and illnesses in the U.S. These injuries are also associated with high costs (about $50 billion annually in the U.S.) to employers due to absenteeism, lost productivity, and increased health care, disability, and workers' compensation costs. To deal with such injuries, manual observation-based ergonomic assessments (e.g., checklists) have been widely used to identify awkward or/and repetitive working postures. However, manual observation methods are time-consuming, expensive and error prone, which makes them difficult to be easily applied to many workplaces. The need for trained analysts is also an obstacle to promote ergonomic assessments in workplaces. As a result, an effective and easily accessible means for ergonomic assessments is required to detect and minimize the risks of ergonomic injuries in a timely-manner. &lt;br/&gt;&lt;br/&gt;The proposed computer vision-based automatic posture analysis approach processes video images of workers taken via ordinary video recording devices like smartphones, tablets, and off-the-shelf camcorders, and consequently evaluates the level of their ergonomic risk they have while performing workplace tasks. The proposed innovation is to make the current ergonomic risk assessment process efficient, affordable, and robust by minimizing time-consuming, expensive, and error prone manual observation. Image sequences of working postures have distinguishable patterns that can be used to differentiate safe and injury-prone postures. By learning these patterns, this technology automatically identifies awkward postures on video recordings, enabling one to conduct ergonomic assessments in a timely manner without technical sophistication or skill. The proposed technical approach is also flexible and robust enough to deal with complex and crowded work environments. Particularly, this innovative virtual modeling approach to automatically create massive training datasets eliminates cumbersome data collection. In addition, the capability to differentiate different postures and realize rapid pose estimation with mobile devices enables the proposed approach to be applied to diverse ergonomic checklists in many industries. This innovation can provide an exciting path for many industries who suffer ergonomic injuries to reduce their burden of manual observation, ultimately opening a door toward the prevention of ergonomic injuries and the increase of productivity.</AbstractNarration>
    <MinAmdLetterDate>01/20/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>01/20/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1623669</AwardID>
    <Investigator>
      <FirstName>SangHyun</FirstName>
      <LastName>Lee</LastName>
      <EmailAddress>shdpm@umich.edu</EmailAddress>
      <StartDate>01/20/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Michigan Ann Arbor</Name>
      <CityName>Ann Arbor</CityName>
      <ZipCode>481091274</ZipCode>
      <PhoneNumber>7347636438</PhoneNumber>
      <StreetAddress>3003 South State St. Room 1062</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Michigan</StateName>
      <StateCode>MI</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8023</Code>
      <Text>I-Corps</Text>
    </ProgramElement>
  </Award>
</rootTag>
