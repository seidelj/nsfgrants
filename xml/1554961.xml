<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Reflection and Diffraction Sound Signals for Non-Field-of-View Target Estimation</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2016</AwardExpirationDate>
    <AwardAmount>165252</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project studies the diffraction and reflection signals in sound source localization. The study could enable the capability of tracking and localizing human partners outside of the robots' Field-Of-View (FOV) to the co-robots for human-robot interaction. The project estimates an object outside of FOV using auditory sensors and enhances perception capabilities of robots. The project integrates research and education by training graduate and undergraduate students and outreach local K-12 students.&lt;br/&gt;&lt;br/&gt;This research proves the early-stage concept of the project that estimates the location of a Non-FOV (NFOV) target by learning from humans and utilizing the physics of sound wave propagation associated with the NFOV target. The research is to introduce the capability of localizing human partners outside of the robots' FOV to the co-robots for Human-Robot Interaction. The research team approaches the problem by deterministically formulating first-arrival diffraction and reflection signals and identifying signal directions. The project develops an approach that auditorily estimates the location of an NFOV target by learning from humans and utilizing the physics of sound wave propagation associated with the NFOV target. The project further evaluates the approach in unknown indoor environments by using both visual and auditory sensors.</AbstractNarration>
    <MinAmdLetterDate>09/01/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>09/01/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1554961</AwardID>
    <Investigator>
      <FirstName>Tomonari</FirstName>
      <LastName>Furukawa</LastName>
      <EmailAddress>tomonari@vt.edu</EmailAddress>
      <StartDate>09/01/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Virginia Polytechnic Institute and State University</Name>
      <CityName>BLACKSBURG</CityName>
      <ZipCode>240610001</ZipCode>
      <PhoneNumber>5402315281</PhoneNumber>
      <StreetAddress>Sponsored Programs 0170</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Virginia</StateName>
      <StateCode>VA</StateCode>
    </Institution>
  </Award>
</rootTag>
