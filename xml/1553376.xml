<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Machine Learning-Based Approaches Toward Combatting Abusive Behavior in Online Communities</AwardTitle>
    <AwardEffectiveDate>02/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>01/31/2021</AwardExpirationDate>
    <AwardAmount>80007</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>William Bainbridge</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This research aims to computationally model abusive online behavior to build tools that help counter it, with the goal of making the Internet a more welcoming place. Since its earliest days, flaming, trolling, harassment and abuse have plagued the Internet. This project will lay bare the structure of online abuse over many types of online conversations, a major step forward for the study of computer-mediated communication. This will result from modeling abuse with statistical machine learning algorithms as a function of theoretically inspired, sociolinguistic variables, and will entail new technical and methodological advances. This work will enable a transformative new class of automated and semi-automated applications that depend on computationally generated abuse predictions. The education and outreach plan is deeply tied to the research activities, and focuses on scaling-up the research's broader impacts. A public application programming interface (API) will enable developers and online community managers around the world to integrate into their own sites the defenses against abuse developed by this research.&lt;br/&gt;&lt;br/&gt;The work will consist of two major phases. In the first, the research will develop a deep understanding of abusive online behavior via statistical machine learning techniques. Specifically, the work will appropriate theories from social science and linguistics to inform the creation of features for robust statistical machine learning algorithms to predict abuse. These proposed abuse models will enable a brand new, transformative class of mixed-initiative artifacts capable of intervening in social media and online communities. In the second phase, this project will explore this newly enabled class of artifacts by building, deploying and evaluating sociotechnical tools for combatting abuse. Specifically, it will explore two classes of tools that use the abuse predictions: shields and moderator tools. The first, shields, will proactively block inbound abuse from reaching people. The second class of tools, moderator tools, will flag and triage abuse for community moderators.</AbstractNarration>
    <MinAmdLetterDate>02/12/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>02/12/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1553376</AwardID>
    <Investigator>
      <FirstName>Eric</FirstName>
      <LastName>Gilbert</LastName>
      <EmailAddress>gilbert@cc.gatech.edu</EmailAddress>
      <StartDate>02/12/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Georgia Tech Research Corporation</Name>
      <CityName>Atlanta</CityName>
      <ZipCode>303320420</ZipCode>
      <PhoneNumber>4048944819</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
  </Award>
</rootTag>
