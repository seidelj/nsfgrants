<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Auditing Algorithms: Adding Accountability to Automated Authority</AwardTitle>
    <AwardEffectiveDate>03/15/2017</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2018</AwardExpirationDate>
    <AwardAmount>49998</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>William Bainbridge</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This grant supports a workshop to coordinate the emerging research community developing "algorithm auditing," a research design that has shown promise in diagnosing the unwanted consequences of algorithmic systems. Automated software-based systems in finance, media, information, transportation, or any application of computing can easily create outcomes that are unforeseeable by their designers, so algorithm auditing has the potential to improve the design of these systems. Auditing in this sense takes its name from the social scientific "audit study" where one feature is manipulated in a field experiment. This workshop proposes to coalesce this new area of inquiry and to produce a report characterizing the state of the art and potential future directions. The topic of algorithm auditing brings together computer science, information science, and social science in novel combinations. Participants will have opportunities to articulate challenges that they face, to present existing methods for auditing, and to propose research agendas that can provide new insights that advance science and benefit society. &lt;br/&gt;&lt;br/&gt;The scientific issues addressed by this workshop are key economic and social impediments to the adoption and development of fundamental advances in information and communication technologies. How humans think about complex algorithms is a fundamental problem in human-computer interaction and cognitive science. There is industrial interest in third-party algorithm auditing as a way to address user dissatisfaction with algorithmic systems and to forestall future problems. Recent research suggests that algorithmic decision-making using "big data" may increase unfairness and structural inequality. Algorithmic systems form a new avenue for the maintenance and transmission of social stratification, and may fuel cumulative disadvantage. Unwanted behavior by algorithmic systems contributes to major societal challenges such as anti-competitive behavior, fraud, unlawful discrimination, and economic and social inequality.</AbstractNarration>
    <MinAmdLetterDate>03/09/2017</MinAmdLetterDate>
    <MaxAmdLetterDate>03/09/2017</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1665151</AwardID>
    <Investigator>
      <FirstName>Christian</FirstName>
      <LastName>Sandvig</LastName>
      <EmailAddress>csandvig@umich.edu</EmailAddress>
      <StartDate>03/09/2017</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Casey</FirstName>
      <LastName>Pierce</LastName>
      <EmailAddress>cbspierc@umich.edu</EmailAddress>
      <StartDate>03/09/2017</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Michigan Ann Arbor</Name>
      <CityName>Ann Arbor</CityName>
      <ZipCode>481091274</ZipCode>
      <PhoneNumber>7347636438</PhoneNumber>
      <StreetAddress>3003 South State St. Room 1062</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Michigan</StateName>
      <StateCode>MI</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8060</Code>
      <Text>Secure &amp;Trustworthy Cyberspace</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>1640</Code>
      <Text>INFORMATION TECHNOLOGY RESEARC</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7556</Code>
      <Text>CONFERENCE AND WORKSHOPS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7434</Code>
      <Text>CNCI</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>1640</Code>
      <Text>INFORMATION TECHNOLOGY RESEARC</Text>
    </ProgramReference>
  </Award>
</rootTag>
