<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Small: Reinforcement Learning in Partially Observable Multi-Agent Tasks</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>85339</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Hector Munoz-Avila</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The goal of this project is to develop new techniques for the design of robot controllers (programs that drive individual autonomous robots) for multi-robot tasks, i.e., tasks involving a collaborative team of robots. Existing techniques that have sound decision and game theoretic properties address simple multi-agent systems. In practice, robot controllers are still largely designed manually. Little is known about the decision theoretic optimality of such controllers, especially in multi-robot settings. This project aims to change that by bridging the gap between multi-agent decision theory and multi-robot control, via three main thrusts. Two of these thrusts seek to modify the ways by which multi-agent decision theory describes and computes these controllers, so as to be applicable to multi-robot tasks. The third thrust seeks to make the new computational approach scale to large robot teams. The project has mixed (theoretical and applied) scope, and will lay the foundation for more principled design of future multi-robot systems. The project will also have broad educational impact. The research will be conducted in collaboration with a graduate and an undergraduate student, and involve hands-on robotics experience for students, as well as generate material for a new undergraduate course on robotics. Any theory and algorithms developed will be shared publicly.&lt;br/&gt;&lt;br/&gt;More specifically, the first main thrust of this project will investigate the expression and game theoretic optimization of behavior based controllers---a popular controller language in the robotics community. Non-linear programming techniques will be used for optimization of modular behaviors, that will be integrated in a hirerchical fashion from simpler to complex tasks. The second main thrust will utilize multi-agent reinforcement learning for the agents/robots to compute their own controllers via joint exploration in task simulations, exploiting inductive knowledge transfer to bootstrap the learning of complex behaviors from simpler, related ones. The third main thrust will develop a new paradigm of multi-agent reinforcement learning---Reinforcement Learning as a Rehearsal (RLaR). Agents will learn in a supervised setting with hidden as well as observable information to reduce sample complexity, but marginalize out the hidden features to yield controllers usable in partially observable settings.</AbstractNarration>
    <MinAmdLetterDate>08/06/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/06/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1526813</AwardID>
    <Investigator>
      <FirstName>Bikramjit</FirstName>
      <LastName>Banerjee</LastName>
      <EmailAddress>Bikramjit.Banerjee@usm.edu</EmailAddress>
      <StartDate>08/06/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Southern Mississippi</Name>
      <CityName>Hattiesburg</CityName>
      <ZipCode>394015876</ZipCode>
      <PhoneNumber>6012664119</PhoneNumber>
      <StreetAddress>2609 WEST 4TH ST</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Mississippi</StateName>
      <StateCode>MS</StateCode>
    </Institution>
  </Award>
</rootTag>
